defmodule VolfefeMachine.Intelligence do
  @moduledoc """
  The Intelligence context.

  Handles ML-based sentiment classification of content using FinBERT.
  This context manages the creation, retrieval, and querying of sentiment
  classifications generated by the FinBERT model.

  ## Architecture

  The Intelligence context follows Phoenix Context boundaries:
  - Calls Content context API (not direct schema access)
  - Manages Classification schema lifecycle
  - Integrates with FinBERT Python service for ML inference
  - Provides public API for other contexts

  ## Model Version

  Classifications track model_version for future model upgrades:
  - Format: "finbert-tone-v1.0"
  - Full metadata stored in meta field
  """

  import Ecto.Query, warn: false
  alias VolfefeMachine.Repo
  alias VolfefeMachine.Intelligence.Classification
  alias VolfefeMachine.Intelligence.ModelClassification
  alias VolfefeMachine.Intelligence.MultiModelClient
  alias VolfefeMachine.Intelligence.Consensus
  alias VolfefeMachine.Content

  @doc """
  Returns the list of classifications.

  ## Examples

      iex> list_classifications()
      [%Classification{}, ...]
  """
  def list_classifications do
    Repo.all(Classification)
  end

  @doc """
  Gets a single classification by ID.

  Raises `Ecto.NoResultsError` if the Classification does not exist.

  ## Examples

      iex> get_classification!(123)
      %Classification{}

      iex> get_classification!(456)
      ** (Ecto.NoResultsError)
  """
  def get_classification!(id), do: Repo.get!(Classification, id)

  @doc """
  Gets the classification for a specific content item.

  Returns nil if no classification exists for the content.

  ## Examples

      iex> get_classification_by_content(content_id)
      %Classification{}

      iex> get_classification_by_content(999)
      nil
  """
  def get_classification_by_content(content_id) do
    Repo.get_by(Classification, content_id: content_id)
  end

  @doc """
  Creates a classification.

  ## Examples

      iex> create_classification(%{
      ...>   content_id: 1,
      ...>   sentiment: "positive",
      ...>   confidence: 0.95,
      ...>   model_version: "finbert-tone-v1.0"
      ...> })
      {:ok, %Classification{}}

      iex> create_classification(%{sentiment: "invalid"})
      {:error, %Ecto.Changeset{}}
  """
  def create_classification(attrs \\ %{}) do
    %Classification{}
    |> Classification.changeset(attrs)
    |> Repo.insert()
  end

  @doc """
  Updates a classification.

  ## Examples

      iex> update_classification(classification, %{confidence: 0.99})
      {:ok, %Classification{}}

      iex> update_classification(classification, %{sentiment: "invalid"})
      {:error, %Ecto.Changeset{}}
  """
  def update_classification(%Classification{} = classification, attrs) do
    classification
    |> Classification.changeset(attrs)
    |> Repo.update()
  end

  @doc """
  Deletes a classification.

  ## Examples

      iex> delete_classification(classification)
      {:ok, %Classification{}}

      iex> delete_classification(classification)
      {:error, %Ecto.Changeset{}}
  """
  def delete_classification(%Classification{} = classification) do
    Repo.delete(classification)
  end

  @doc """
  Returns an `%Ecto.Changeset{}` for tracking classification changes.

  ## Examples

      iex> change_classification(classification)
      %Ecto.Changeset{data: %Classification{}}
  """
  def change_classification(%Classification{} = classification, attrs \\ %{}) do
    Classification.changeset(classification, attrs)
  end

  @doc """
  Classifies a content item using FinBERT.

  This is the main entry point for sentiment classification. It:
  1. Fetches the content item
  2. Calls the FinBERT service for classification
  3. Stores the classification result
  4. Returns the classification

  ## Examples

      iex> classify_content(content_id)
      {:ok, %Classification{sentiment: "positive", confidence: 0.95}}

      iex> classify_content(999)
      {:error, :content_not_found}

      iex> classify_content(content_id_with_empty_text)
      {:error, :no_text_to_classify}
  """
  def classify_content(content_id) do
    with {:ok, content} <- fetch_content(content_id),
         {:ok, text} <- validate_text(content),
         {:ok, result} <- call_finbert_service(text),
         {:ok, classification} <- store_classification(content_id, result) do
      {:ok, classification}
    end
  end

  @doc """
  Classifies a content item using ALL configured sentiment models.

  This is the new multi-model classification approach:
  1. Fetches the content item
  2. Calls multi-model Python script for all models
  3. Stores individual model classifications in model_classifications table
  4. Calculates weighted consensus
  5. Stores/updates consensus in classifications table
  6. Returns both consensus and individual model results

  ## Examples

      iex> classify_content_multi_model(content_id)
      {:ok, %{
        consensus: %Classification{sentiment: "negative", confidence: 0.85},
        model_results: [
          %ModelClassification{model_id: "distilbert", sentiment: "negative", ...},
          %ModelClassification{model_id: "twitter_roberta", sentiment: "negative", ...},
          %ModelClassification{model_id: "finbert", sentiment: "neutral", ...}
        ]
      }}

      iex> classify_content_multi_model(999)
      {:error, :content_not_found}
  """
  def classify_content_multi_model(content_id) do
    with {:ok, content} <- fetch_content(content_id),
         {:ok, text} <- validate_text(content),
         {:ok, multi_results} <- call_multi_model_service(text) do
      # Wrap database operations in transaction to ensure atomicity
      # If consensus storage fails, model_classifications are rolled back
      case Repo.transaction(fn ->
        with {:ok, model_classifications} <- store_model_classifications(content_id, multi_results),
             {:ok, consensus} <- calculate_and_store_consensus(content_id, model_classifications) do
          %{
            consensus: consensus,
            model_results: model_classifications,
            metadata: %{
              total_latency_ms: multi_results.total_latency_ms,
              models_used: multi_results.models_used,
              successful_models: multi_results.successful_models
            }
          }
        else
          {:error, reason} -> Repo.rollback(reason)
        end
      end) do
        {:ok, result} -> {:ok, result}
        {:error, reason} -> {:error, reason}
      end
    end
  end

  @doc """
  Batch classifies multiple content items.

  Returns a list of results with {:ok, classification} or {:error, reason}
  for each content ID.

  ## Examples

      iex> batch_classify_contents([1, 2, 3])
      [
        {:ok, %Classification{}},
        {:ok, %Classification{}},
        {:error, :no_text_to_classify}
      ]
  """
  def batch_classify_contents(content_ids) when is_list(content_ids) do
    Enum.map(content_ids, &classify_content/1)
  end

  @doc """
  Batch classifies multiple content items using multi-model approach.

  Returns a list of results with {:ok, result} or {:error, reason}
  for each content ID.

  ## Examples

      iex> batch_classify_contents_multi_model([1, 2, 3])
      [
        {:ok, %{consensus: %Classification{}, model_results: [...]}},
        {:ok, %{consensus: %Classification{}, model_results: [...]}},
        {:error, :no_text_to_classify}
      ]
  """
  def batch_classify_contents_multi_model(content_ids) when is_list(content_ids) do
    Enum.map(content_ids, &classify_content_multi_model/1)
  end

  @doc """
  Queries classifications by sentiment.

  ## Examples

      iex> list_by_sentiment("positive")
      [%Classification{sentiment: "positive"}, ...]
  """
  def list_by_sentiment(sentiment) when sentiment in ["positive", "negative", "neutral"] do
    Classification
    |> where([c], c.sentiment == ^sentiment)
    |> Repo.all()
  end

  @doc """
  Queries classifications with confidence above a threshold.

  ## Examples

      iex> list_high_confidence(0.9)
      [%Classification{confidence: 0.95}, ...]
  """
  def list_high_confidence(threshold) when is_float(threshold) do
    Classification
    |> where([c], c.confidence >= ^threshold)
    |> Repo.all()
  end

  ## Monitoring & Analysis Queries

  @doc """
  Get recent classifications within the last N hours.
  Uses the inserted_at index for efficient querying.

  ## Examples

      iex> recent_classifications(24)
      [%Classification{}, ...]

      iex> recent_classifications(1)
      [%Classification{inserted_at: ~U[2025-10-26 18:30:00Z]}, ...]
  """
  def recent_classifications(hours \\ 24) do
    cutoff = DateTime.utc_now() |> DateTime.add(-hours * 3600, :second)

    Classification
    |> where([c], c.inserted_at >= ^cutoff)
    |> order_by([c], desc: c.inserted_at)
    |> preload(:content)
    |> Repo.all()
  end

  @doc """
  Calculate average processing latency from meta.processing.latency_ms.

  ## Examples

      iex> avg_latency()
      3245.5
  """
  def avg_latency do
    Repo.one(
      from c in Classification,
        select: avg(fragment("(meta->'processing'->>'latency_ms')::int"))
    )
  end

  @doc """
  Find slow classifications (>5000ms by default).

  ## Examples

      iex> slow_classifications()
      [%Classification{}, ...]

      iex> slow_classifications(10000)
      [%Classification{}, ...]
  """
  def slow_classifications(threshold_ms \\ 5000) do
    Classification
    |> where(
      [c],
      fragment("(meta->'processing'->>'latency_ms')::int > ?", ^threshold_ms)
    )
    |> order_by([c], desc: fragment("(meta->'processing'->>'latency_ms')::int"))
    |> preload(:content)
    |> Repo.all()
  end

  @doc """
  Find ambiguous classifications with low score margin (<0.3 by default).

  ## Examples

      iex> ambiguous_classifications()
      [%Classification{}, ...]

      iex> ambiguous_classifications(0.2)
      [%Classification{}, ...]
  """
  def ambiguous_classifications(margin_threshold \\ 0.3) do
    Classification
    |> where(
      [c],
      fragment("(meta->'quality'->>'score_margin')::float < ?", ^margin_threshold)
    )
    |> preload(:content)
    |> Repo.all()
  end

  @doc """
  Get sentiment distribution across all classifications.

  ## Examples

      iex> sentiment_distribution()
      %{"positive" => 51, "neutral" => 34, "negative" => 2}
  """
  def sentiment_distribution do
    Classification
    |> group_by([c], c.sentiment)
    |> select([c], {c.sentiment, count(c.id)})
    |> Repo.all()
    |> Enum.into(%{})
  end

  @doc """
  Get confidence distribution by ranges.

  ## Examples

      iex> confidence_distribution()
      %{high: 80, medium: 15, low: 5}
  """
  def confidence_distribution do
    %{
      high:
        Repo.aggregate(
          from(c in Classification, where: c.confidence >= 0.9),
          :count,
          :id
        ),
      medium:
        Repo.aggregate(
          from(c in Classification, where: c.confidence >= 0.7 and c.confidence < 0.9),
          :count,
          :id
        ),
      low:
        Repo.aggregate(
          from(c in Classification, where: c.confidence < 0.7),
          :count,
          :id
        )
    }
  end

  @doc """
  Get comprehensive statistics about all classifications.

  ## Examples

      iex> get_stats()
      %{
        total: 87,
        sentiment: %{"positive" => 51, "neutral" => 34, "negative" => 2},
        confidence: %{high: 80, medium: 7, low: 0},
        avg_confidence: 0.9809,
        avg_latency_ms: 3245.5
      }
  """
  def get_stats do
    total = Repo.aggregate(Classification, :count, :id)
    avg_confidence = Repo.one(from c in Classification, select: avg(c.confidence))

    %{
      total: total,
      sentiment: sentiment_distribution(),
      confidence: confidence_distribution(),
      avg_confidence: if(avg_confidence, do: Float.round(avg_confidence, 4), else: 0.0),
      avg_latency_ms: avg_latency()
    }
  end

  # Private helper functions

  defp fetch_content(content_id) do
    case Content.get_content(content_id) do
      nil -> {:error, :content_not_found}
      content -> {:ok, content}
    end
  end

  defp validate_text(%{text: text}) when is_binary(text) do
    case String.trim(text) do
      "" -> {:error, :no_text_to_classify}
      _ -> {:ok, text}
    end
  end

  defp validate_text(_), do: {:error, :no_text_to_classify}

  defp call_finbert_service(text) do
    alias VolfefeMachine.Intelligence.FinbertClient

    case FinbertClient.classify(text) do
      {:ok, result} -> {:ok, result}
      {:error, reason} -> {:error, reason}
    end
  end

  defp store_classification(content_id, result) do
    attrs = %{
      content_id: content_id,
      sentiment: result.sentiment,
      confidence: result.confidence,
      model_version: result.model_version,
      meta: result.meta
    }

    create_classification(attrs)
  end

  # Multi-model classification helpers

  defp call_multi_model_service(text) do
    case MultiModelClient.classify(text) do
      {:ok, results} -> {:ok, results}
      {:error, reason} -> {:error, reason}
    end
  end

  defp store_model_classifications(content_id, multi_results) do
    # Store each model's classification result
    results = multi_results.results

    stored_classifications =
      Enum.reduce_while(results, {:ok, []}, fn result, {:ok, acc} ->
        # Skip models that failed
        if Map.has_key?(result, :error) do
          {:cont, {:ok, acc}}
        else
          attrs = %{
            content_id: content_id,
            model_id: result.model_id,
            model_version: result.model_version,
            sentiment: result.sentiment,
            confidence: result.confidence,
            meta: result.meta
          }

          case ModelClassification.changeset(%ModelClassification{}, attrs) |> Repo.insert() do
            {:ok, model_classification} ->
              {:cont, {:ok, [model_classification | acc]}}

            {:error, changeset} ->
              {:halt, {:error, {:model_classification_failed, changeset}}}
          end
        end
      end)

    case stored_classifications do
      {:ok, classifications} -> {:ok, Enum.reverse(classifications)}
      error -> error
    end
  end

  defp calculate_and_store_consensus(content_id, model_classifications) do
    # Convert ModelClassification structs to maps for Consensus module
    model_results =
      Enum.map(model_classifications, fn mc ->
        %{
          model_id: mc.model_id,
          sentiment: mc.sentiment,
          confidence: mc.confidence
        }
      end)

    case Consensus.calculate(model_results) do
      {:ok, consensus_result} ->
        # Store or update consensus classification using upsert to avoid race conditions
        attrs = %{
          content_id: content_id,
          sentiment: consensus_result.sentiment,
          confidence: consensus_result.confidence,
          model_version: consensus_result.model_version,
          meta: consensus_result.meta
        }

        # Use upsert with on_conflict to handle concurrent inserts elegantly
        # The unique constraint on content_id makes this safe from TOCTOU races
        %Classification{}
        |> Classification.changeset(attrs)
        |> Repo.insert(
          on_conflict: {:replace, [:sentiment, :confidence, :model_version, :meta, :updated_at]},
          conflict_target: :content_id
        )

      {:error, reason} ->
        {:error, reason}
    end
  end
end
